{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a85602af-ac8a-43d6-9654-2ccd66800603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration and Setup\n",
    "storage_account = \"adls4salesdata\"\n",
    "silver_container = \"transformed-data\"\n",
    "gold_container = \"ready-data\"\n",
    "account_key = "keygoeshere"\"\n",
    "\n",
    "# Configure storage access\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account}.blob.core.windows.net\", account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b4ee1d1-8031-4d52-83d7-09ad7c1984a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold layer configuration completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Configure storage paths\n",
    "silver_base_path = f\"wasbs://{silver_container}@{storage_account}.blob.core.windows.net\"\n",
    "gold_base_path = f\"wasbs://{gold_container}@{storage_account}.blob.core.windows.net\"\n",
    "\n",
    "\n",
    "# Configure Spark for optimized performance\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.skew.enabled\", \"true\")\n",
    "\n",
    "print(\"Gold layer configuration completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05c16361-b01c-4df4-9ce7-988d5caa2906",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== READING GOLD LAYER DATA ===\n✓ Gold layer data loaded successfully!\n\n=== GOLD LAYER SCHEMAS ===\nFact Sales Schema:\nroot\n |-- SalesKey: string (nullable = true)\n |-- DateKey: date (nullable = true)\n |-- Year: integer (nullable = true)\n |-- Quarter: integer (nullable = true)\n |-- Month: integer (nullable = true)\n |-- Day: integer (nullable = true)\n |-- CustomerKey: string (nullable = true)\n |-- ProductKey: string (nullable = true)\n |-- StoreKey: string (nullable = true)\n |-- TransactionID: integer (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- TotalSales: double (nullable = true)\n |-- CostPrice: double (nullable = true)\n |-- Profit: double (nullable = true)\n |-- Lineage: string (nullable = true)\n\n\nFact Customer Metrics Schema:\nroot\n |-- DateKey: date (nullable = true)\n |-- CustomerKey: string (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- TotalTransactions: long (nullable = true)\n |-- TotalSpend: double (nullable = true)\n |-- TotalItemsPurchased: long (nullable = true)\n |-- AvgTransactionValue: double (nullable = true)\n |-- UniqueProductsPurchased: long (nullable = true)\n |-- FirstPurchaseDate: date (nullable = true)\n |-- LastPurchaseDate: date (nullable = true)\n |-- CustomerValueSegment: string (nullable = true)\n |-- Lineage: string (nullable = true)\n\n\nFact Product Performance Schema:\nroot\n |-- DateKey: date (nullable = true)\n |-- ProductKey: string (nullable = true)\n |-- ProductID: integer (nullable = true)\n |-- TotalSalesTransactions: long (nullable = true)\n |-- TotalUnitsSold: long (nullable = true)\n |-- TotalRevenue: double (nullable = true)\n |-- TotalCost: double (nullable = true)\n |-- TotalProfit: double (nullable = true)\n |-- AvgSaleValue: double (nullable = true)\n |-- ProfitMargin: double (nullable = true)\n |-- UniqueCustomers: long (nullable = true)\n |-- Lineage: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Read Gold Layer Data and Perform Analysis\n",
    "print(\"=== READING GOLD LAYER DATA ===\")\n",
    "\n",
    "# Read dimension tables from Gold layer\n",
    "dim_customer_gold = spark.read.parquet(f\"{gold_base_path}/dimensions/dim_customer\")\n",
    "dim_product_gold = spark.read.parquet(f\"{gold_base_path}/dimensions/dim_product\")\n",
    "dim_store_gold = spark.read.parquet(f\"{gold_base_path}/dimensions/dim_store\")\n",
    "\n",
    "# Read fact tables from Gold layer\n",
    "fact_sales_gold = spark.read.parquet(f\"{gold_base_path}/facts/fact_sales\")\n",
    "fact_customer_metrics_gold = spark.read.parquet(f\"{gold_base_path}/facts/fact_customer_metrics\")\n",
    "fact_product_performance_gold = spark.read.parquet(f\"{gold_base_path}/facts/fact_product_performance\")\n",
    "\n",
    "# Read business KPIs\n",
    "monthly_revenue_kpi = spark.read.parquet(f\"{gold_base_path}/business_kpis/monthly_revenue_kpi\")\n",
    "customer_segmentation_kpi = spark.read.parquet(f\"{gold_base_path}/business_kpis/customer_segmentation_kpi\")\n",
    "category_performance_kpi = spark.read.parquet(f\"{gold_base_path}/business_kpis/category_performance_kpi\")\n",
    "\n",
    "print(\"✓ Gold layer data loaded successfully!\")\n",
    "\n",
    "# Display schema to understand available columns\n",
    "print(\"\\n=== GOLD LAYER SCHEMAS ===\")\n",
    "print(\"Fact Sales Schema:\")\n",
    "fact_sales_gold.printSchema()\n",
    "\n",
    "print(\"\\nFact Customer Metrics Schema:\")\n",
    "fact_customer_metrics_gold.printSchema()\n",
    "\n",
    "print(\"\\nFact Product Performance Schema:\")\n",
    "fact_product_performance_gold.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad5d8b8d-ae96-413a-8282-dff60452fdc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== GOLD LAYER DATA OVERVIEW ===\nDimCustomer: 1,000 records\nDimProduct: 200 records\nDimStore: 10 records\nFactSales: 84,766 records\nFactCustomerMetrics: 1,000 records\nFactProductPerformance: 200 records\n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics\n",
    "print(\"\\n=== GOLD LAYER DATA OVERVIEW ===\")\n",
    "print(f\"DimCustomer: {dim_customer_gold.count():,} records\")\n",
    "print(f\"DimProduct: {dim_product_gold.count():,} records\")\n",
    "print(f\"DimStore: {dim_store_gold.count():,} records\")\n",
    "print(f\"FactSales: {fact_sales_gold.count():,} records\")\n",
    "print(f\"FactCustomerMetrics: {fact_customer_metrics_gold.count():,} records\")\n",
    "print(f\"FactProductPerformance: {fact_product_performance_gold.count():,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2055a84d-66f8-4fa6-94a9-d3a993eb1564",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Temporary views created for SparkSQL\n"
     ]
    }
   ],
   "source": [
    "# Create temporary views for SparkSQL\n",
    "dim_customer_gold.createOrReplaceTempView(\"dim_customer\")\n",
    "dim_product_gold.createOrReplaceTempView(\"dim_product\")\n",
    "dim_store_gold.createOrReplaceTempView(\"dim_store\")\n",
    "fact_sales_gold.createOrReplaceTempView(\"fact_sales\")\n",
    "fact_customer_metrics_gold.createOrReplaceTempView(\"fact_customer_metrics\")\n",
    "fact_product_performance_gold.createOrReplaceTempView(\"fact_product_performance\")\n",
    "monthly_revenue_kpi.createOrReplaceTempView(\"monthly_revenue_kpi\")\n",
    "customer_segmentation_kpi.createOrReplaceTempView(\"customer_segmentation_kpi\")\n",
    "category_performance_kpi.createOrReplaceTempView(\"category_performance_kpi\")\n",
    "\n",
    "print(\"✓ Temporary views created for SparkSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f839a3dd-616c-4dbf-80b9-cb30a33d8669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Perform Comprehensive Analysis using SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "906a19bc-37e5-4156-b72a-f4c726663204",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nCOMPREHENSIVE BUSINESS INTELLIGENCE ANALYSIS\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Perform Comprehensive Analysis using SparkSQL\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE BUSINESS INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "196b59e4-7e2c-44a9-82e4-b3a62321e8b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. EXECUTIVE SUMMARY - FIXED VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9173a62e-a869-4706-8ae2-b8c8e2dc6b3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. EXECUTIVE SUMMARY - FIXED VERSION\n",
    "print(\"\\n1. EXECUTIVE BUSINESS SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "executive_summary = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT c.CustomerAlternateKey) as total_customers,\n",
    "    COUNT(DISTINCT p.ProductAlternateKey) as total_products,\n",
    "    COUNT(DISTINCT s.StoreAlternateKey) as total_stores,\n",
    "    SUM(f.TotalSales) as total_revenue,\n",
    "    SUM(f.Profit) as total_profit,\n",
    "    AVG(f.Profit) as avg_profit_per_transaction,\n",
    "    COUNT(f.TransactionID) as total_transactions,\n",
    "    SUM(f.Quantity) as total_units_sold\n",
    "FROM fact_sales f\n",
    "LEFT JOIN dim_customer c ON f.CustomerKey = c.CustomerKey\n",
    "LEFT JOIN dim_product p ON f.ProductKey = p.ProductKey\n",
    "LEFT JOIN dim_store s ON f.StoreKey = s.StoreKey\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDCCA Overall Business Performance:\")\n",
    "executive_summary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a62ed8b-3cb4-4f98-9f1a-2fb96706db3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. REVENUE ANALYSIS BY TIME PERIOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "515c4234-f4d8-4c64-8917-3c1e1ee2a7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n2. REVENUE TREND ANALYSIS\n----------------------------------------\n\uD83D\uDCC8 Monthly Revenue Trend:\n+----+-----+-----------------+------------------+-----------------+-----------------+----------------+\n|Year|Month|monthly_revenue  |monthly_profit    |avg_profit_margin|transaction_count|unique_customers|\n+----+-----+-----------------+------------------+-----------------+-----------------+----------------+\n|2024|1    |4659445.179999996|3645154.4600000028|78.23151296309501|7116             |1000            |\n|2024|2    |4376766.050000001|3427584.8000000017|78.31318285792317|6636             |999             |\n|2024|3    |4722583.090000004|3668828.3400000017|77.68689867561439|7215             |998             |\n|2024|4    |4755772.239999998|3709125.76        |77.99208147108409|6956             |1000            |\n|2024|5    |5026723.059999994|3946822.76        |78.51681329744878|7306             |998             |\n|2024|6    |4607429.23       |3609537.8599999985|78.34168860364673|6951             |999             |\n|2024|7    |4881313.559999999|3813245.499999999 |78.11924911457645|7268             |999             |\n|2024|8    |4774952.420000002|3716096.8800000027|77.82479390653282|7243             |1000            |\n|2024|9    |4690556.330000002|3672995.5900000017|78.30618228605731|6802             |1000            |\n|2024|10   |4940984.540000001|3873755.8899999964|78.4004859484947 |7322             |999             |\n|2024|11   |4518234.369999999|3531066.7000000016|78.15147269573805|6848             |1000            |\n|2024|12   |4711533.729999999|3698142.3300000005|78.49126297138919|7103             |999             |\n+----+-----+-----------------+------------------+-----------------+-----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 2. REVENUE ANALYSIS BY TIME PERIOD\n",
    "print(\"\\n2. REVENUE TREND ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "revenue_trend = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Year,\n",
    "    Month,\n",
    "    SUM(MonthlyRevenue) as monthly_revenue,\n",
    "    SUM(MonthlyProfit) as monthly_profit,\n",
    "    AVG(ProfitMargin) as avg_profit_margin,\n",
    "    SUM(TransactionCount) as transaction_count,\n",
    "    SUM(UniqueCustomers) as unique_customers\n",
    "FROM monthly_revenue_kpi\n",
    "GROUP BY Year, Month\n",
    "ORDER BY Year, Month\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDCC8 Monthly Revenue Trend:\")\n",
    "revenue_trend.show(30, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b94c287-de8d-4e83-b70c-4993858e27aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. CUSTOMER SEGMENTATION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccedafc7-b871-4d2e-8697-575b71a5bbda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n3. CUSTOMER SEGMENTATION ANALYSIS\n----------------------------------------\n\uD83D\uDC65 Customer Value Segmentation:\n+--------------------+-------------+-------------------+------------------+-----------------------------+----------------------------+\n|CustomerValueSegment|CustomerCount|SegmentRevenue     |avg_customer_value|avg_transactions_per_customer|revenue_contribution_percent|\n+--------------------+-------------+-------------------+------------------+-----------------------------+----------------------------+\n|Platinum            |1000         |5.666629380000005E7|56666.29          |84.77                        |100.0                       |\n+--------------------+-------------+-------------------+------------------+-----------------------------+----------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 3. CUSTOMER SEGMENTATION ANALYSIS\n",
    "print(\"\\n3. CUSTOMER SEGMENTATION ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "customer_segmentation = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CustomerValueSegment,\n",
    "    CustomerCount,\n",
    "    SegmentRevenue,\n",
    "    ROUND(AvgCustomerValue, 2) as avg_customer_value,\n",
    "    ROUND(AvgTransactionsPerCustomer, 2) as avg_transactions_per_customer,\n",
    "    ROUND(SegmentRevenue / SUM(SegmentRevenue) OVER() * 100, 2) as revenue_contribution_percent\n",
    "FROM customer_segmentation_kpi\n",
    "ORDER BY SegmentRevenue DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDC65 Customer Value Segmentation:\")\n",
    "customer_segmentation.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e517064-aa2f-4f76-9889-d2d64bf741f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4. PRODUCT PERFORMANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c82bd319-577b-4a46-8b86-2dad4383bc58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Top 10 products by revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a6bfa0c-1308-4ddb-8c39-0c8951377bc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDFC6 Top 10 Products by Revenue:\n+------------------+--------+-------+------------------+------------------+-------------+--------------+---------------+\n|ProductName       |Category|Brand  |total_revenue     |total_profit      |profit_margin|TotalUnitsSold|UniqueCustomers|\n+------------------+--------+-------+------------------+------------------+-------------+--------------+---------------+\n|LG Smart Watch    |1       |LG     |2534879.78        |1970028.6999999955|77.72        |1333          |350            |\n|LG Headphones     |1       |LG     |2304587.030000004 |1739966.1500000013|75.5         |1455          |393            |\n|Samsung Smartphone|1       |Samsung|2252210.520000006 |1830683.520000006 |81.28        |1255          |341            |\n|Dell Headphones   |1       |Dell   |2200639.940000008 |1724279.0000000086|78.35        |1187          |332            |\n|JBL Headphones    |1       |JBL    |2195410.5199999996|1618708.5200000026|73.73        |1278          |344            |\n|Bose Laptop       |1       |Bose   |1865876.860000005 |1474583.6400000039|79.03        |1212          |317            |\n|HP Smartphone     |1       |HP     |1841770.6800000053|1421560.6800000053|77.18        |1254          |345            |\n|JBL Smartphone    |1       |JBL    |1721865.69        |1292309.3499999982|75.05        |1174          |336            |\n|LG Smartphone     |1       |LG     |1671111.1399999973|1386323.5799999963|82.96        |1285          |334            |\n|Lenovo Tablet     |1       |Lenovo |1530703.519999999 |1190840.04        |77.8         |1389          |364            |\n+------------------+--------+-------+------------------+------------------+-------------+--------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Top 10 products by revenue\n",
    "top_products = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    p.ProductName,\n",
    "    p.Category,\n",
    "    p.Brand,\n",
    "    SUM(f.TotalRevenue) as total_revenue,\n",
    "    SUM(f.TotalProfit) as total_profit,\n",
    "    ROUND(f.ProfitMargin, 2) as profit_margin,\n",
    "    f.TotalUnitsSold,\n",
    "    f.UniqueCustomers\n",
    "FROM fact_product_performance f\n",
    "JOIN dim_product p ON f.ProductKey = p.ProductKey\n",
    "GROUP BY p.ProductName, p.Category, p.Brand, f.ProfitMargin, f.TotalUnitsSold, f.UniqueCustomers\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83C\uDFC6 Top 10 Products by Revenue:\")\n",
    "top_products.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2de05c91-2506-4100-ad6e-ec9946ee1f4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. CATEGORY PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a69ddc9-fccf-45ce-8197-7e992ac9a308",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n5. PRODUCT CATEGORY PERFORMANCE\n----------------------------------------\n\uD83D\uDCE6 Category Performance Analysis:\n+--------+-------------------+-------------------+-------------+--------------+------------+-----------------------+--------------------+\n|Category|CategoryRevenue    |CategoryProfit     |profit_margin|TotalUnitsSold|ProductCount|avg_revenue_per_product|market_share_percent|\n+--------+-------------------+-------------------+-------------+--------------+------------+-----------------------+--------------------+\n|1       |3.246549102000003E7|2.539078266000002E7|78.21        |33262         |26          |1248672.73             |57.29               |\n|8       |5526959.780000003  |4340162.710000004  |78.53        |26610         |21          |263188.56              |9.75                |\n|2       |5227575.1999999955 |4095534.959999996  |78.34        |22601         |18          |290420.84              |9.23                |\n|3       |4614832.620000003  |3602020.970000002  |78.05        |45090         |35          |131852.36              |8.14                |\n|5       |4584233.969999999  |3570040.81         |77.88        |29646         |23          |199314.52              |8.09                |\n|7       |1711492.79         |1318299.07         |77.03        |31198         |25          |68459.71               |3.02                |\n|4       |1309138.6500000004 |1034228.2900000002 |79.0         |44511         |35          |37403.96               |2.31                |\n|6       |1226569.77         |961287.3999999998  |78.37        |21758         |17          |72151.16               |2.16                |\n+--------+-------------------+-------------------+-------------+--------------+------------+-----------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5. PRODUCT CATEGORY PERFORMANCE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "category_performance = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Category,\n",
    "    CategoryRevenue,\n",
    "    CategoryProfit,\n",
    "    ROUND(ProfitMargin, 2) as profit_margin,\n",
    "    TotalUnitsSold,\n",
    "    ProductCount,\n",
    "    ROUND(AvgRevenuePerProduct, 2) as avg_revenue_per_product,\n",
    "    ROUND(CategoryRevenue / SUM(CategoryRevenue) OVER() * 100, 2) as market_share_percent\n",
    "FROM category_performance_kpi\n",
    "ORDER BY CategoryRevenue DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDCE6 Category Performance Analysis:\")\n",
    "category_performance.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c72e9071-4317-4cdb-b893-1c4b6e79eb0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. CUSTOMER BEHAVIOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63792afc-7e10-4476-a3bb-7084d6d82ebd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n6. CUSTOMER BEHAVIOR INSIGHTS\n----------------------------------------\n\uD83D\uDC64 Customer Behavior by Segment:\n+---------------+--------------+---------+----------------+---------------------+-------------------+\n|CustomerSegment|customer_count|avg_spend|avg_transactions|avg_transaction_value|avg_unique_products|\n+---------------+--------------+---------+----------------+---------------------+-------------------+\n|Domestic       |1000          |56666.29 |84.77           |668.08               |69.18              |\n+---------------+--------------+---------+----------------+---------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 6. CUSTOMER BEHAVIOR ANALYSIS\n",
    "print(\"\\n6. CUSTOMER BEHAVIOR INSIGHTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "customer_behavior = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    c.CustomerSegment,\n",
    "    COUNT(*) as customer_count,\n",
    "    ROUND(AVG(m.TotalSpend), 2) as avg_spend,\n",
    "    ROUND(AVG(m.TotalTransactions), 2) as avg_transactions,\n",
    "    ROUND(AVG(m.AvgTransactionValue), 2) as avg_transaction_value,\n",
    "    ROUND(AVG(m.UniqueProductsPurchased), 2) as avg_unique_products\n",
    "FROM fact_customer_metrics m\n",
    "JOIN dim_customer c ON m.CustomerKey = c.CustomerKey\n",
    "GROUP BY c.CustomerSegment\n",
    "ORDER BY avg_spend DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDC64 Customer Behavior by Segment:\")\n",
    "customer_behavior.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9424b75f-073d-4e63-b338-5a6f88c5fbae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. STORE PERFORMANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81ce074e-b22d-4ef1-b00f-83c17db995d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7. STORE PERFORMANCE ANALYSIS\n",
    "print(\"\\n7. STORE PERFORMANCE ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "store_performance = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    s.StoreName,\n",
    "    s.Region,\n",
    "    s.City,\n",
    "    s.State,\n",
    "    COUNT(f.TransactionID) as transaction_count,\n",
    "    ROUND(SUM(f.TotalSales), 2) as total_revenue,\n",
    "    ROUND(SUM(f.Profit), 2) as total_profit,\n",
    "    ROUND(AVG(f.Profit), 2) as avg_profit_per_transaction,\n",
    "    COUNT(DISTINCT f.CustomerKey) as unique_customers\n",
    "FROM fact_sales f\n",
    "JOIN dim_store s ON f.StoreKey = s.StoreKey\n",
    "GROUP BY s.StoreName, s.Region, s.City, s.State\n",
    "ORDER BY total_revenue DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83C\uDFEA Store Performance Ranking:\")\n",
    "store_performance.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a72c21e-8d8b-4912-beff-9e8ae6c5ff81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 8. SEASONALITY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e55e23de-359e-4812-be2c-0b9384a87dac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n8. SEASONAL SALES PATTERNS\n----------------------------------------\n\uD83D\uDCC5 Monthly Sales Patterns:\n+-----+----+------------------+------------------+-----------------+---------------------+\n|Month|Year|monthly_sales     |monthly_profit    |transaction_count|avg_transaction_value|\n+-----+----+------------------+------------------+-----------------+---------------------+\n|1    |2024|4659445.179999998 |3645154.4600000056|7116             |654.78               |\n|2    |2024|4376766.0500000045|3427584.8000000054|6636             |659.55               |\n|3    |2024|4722583.090000003 |3668828.3400000045|7215             |654.55               |\n|4    |2024|4755772.240000004 |3709125.7600000054|6956             |683.69               |\n|5    |2024|5026723.059999995 |3946822.76000001  |7306             |688.03               |\n|6    |2024|4607429.230000002 |3609537.860000008 |6951             |662.84               |\n|7    |2024|4881313.560000005 |3813245.5000000075|7268             |671.62               |\n|8    |2024|4774952.419999999 |3716096.880000008 |7243             |659.25               |\n|9    |2024|4690556.329999999 |3672995.5900000045|6802             |689.58               |\n|10   |2024|4940984.540000003 |3873755.8900000085|7322             |674.81               |\n|11   |2024|4518234.369999997 |3531066.700000007 |6848             |659.79               |\n|12   |2024|4711533.73        |3698142.330000006 |7103             |663.32               |\n+-----+----+------------------+------------------+-----------------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 8. SEASONALITY ANALYSIS\n",
    "print(\"\\n8. SEASONAL SALES PATTERNS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "seasonality = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Month,\n",
    "    Year,\n",
    "    SUM(TotalSales) as monthly_sales,\n",
    "    SUM(Profit) as monthly_profit,\n",
    "    COUNT(TransactionID) as transaction_count,\n",
    "    ROUND(AVG(TotalSales), 2) as avg_transaction_value\n",
    "FROM fact_sales\n",
    "GROUP BY Year, Month\n",
    "ORDER BY Year, Month\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDCC5 Monthly Sales Patterns:\")\n",
    "seasonality.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ec91d31-a9fd-4fb4-97eb-aa0927f6e087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 9. CUSTOMER LIFETIME VALUE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6562b36e-f2bf-4684-a244-aceef53039ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n9. CUSTOMER LIFETIME VALUE ANALYSIS\n----------------------------------------\n\uD83D\uDCB0 Customer Lifetime Value Analysis:\n+--------------------+--------------+---------+---------+---------+----------------+----------------------+\n|CustomerValueSegment|customer_count|min_spend|max_spend|avg_spend|avg_transactions|avg_products_purchased|\n+--------------------+--------------+---------+---------+---------+----------------+----------------------+\n|Platinum            |1000          |20503.47 |112942.5 |56666.29 |84.77           |69.18                 |\n+--------------------+--------------+---------+---------+---------+----------------+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 9. CUSTOMER LIFETIME VALUE ANALYSIS\n",
    "print(\"\\n9. CUSTOMER LIFETIME VALUE ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "clv_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CustomerValueSegment,\n",
    "    COUNT(*) as customer_count,\n",
    "    ROUND(MIN(TotalSpend), 2) as min_spend,\n",
    "    ROUND(MAX(TotalSpend), 2) as max_spend,\n",
    "    ROUND(AVG(TotalSpend), 2) as avg_spend,\n",
    "    ROUND(AVG(TotalTransactions), 2) as avg_transactions,\n",
    "    ROUND(AVG(UniqueProductsPurchased), 2) as avg_products_purchased\n",
    "FROM fact_customer_metrics\n",
    "GROUP BY CustomerValueSegment\n",
    "ORDER BY avg_spend DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDCB0 Customer Lifetime Value Analysis:\")\n",
    "clv_analysis.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea829c87-1b50-4034-9a06-6d5e61a89a6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 10. PROFITABILITY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8475895-a49f-40ae-bd81-8ecbca90545c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n10. PROFITABILITY ANALYSIS\n----------------------------------------\n\uD83D\uDCB9 Overall Profitability Metrics:\n+---------------------+-------------------------+--------------------+----------------------+-------------------+\n|overall_profit_margin|avg_product_profit_margin|high_margin_products|medium_margin_products|low_margin_products|\n+---------------------+-------------------------+--------------------+----------------------+-------------------+\n|78.2                 |78.1                     |200                 |0                     |0                  |\n+---------------------+-------------------------+--------------------+----------------------+-------------------+\n\n\n================================================================================\nADVANCED ANALYTICS WITH WINDOW FUNCTIONS\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 10. PROFITABILITY ANALYSIS\n",
    "print(\"\\n10. PROFITABILITY ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "profitability = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    ROUND(SUM(TotalProfit) / SUM(TotalRevenue) * 100, 2) as overall_profit_margin,\n",
    "    ROUND(AVG(ProfitMargin), 2) as avg_product_profit_margin,\n",
    "    COUNT(CASE WHEN ProfitMargin > 20 THEN 1 END) as high_margin_products,\n",
    "    COUNT(CASE WHEN ProfitMargin BETWEEN 10 AND 20 THEN 1 END) as medium_margin_products,\n",
    "    COUNT(CASE WHEN ProfitMargin < 10 THEN 1 END) as low_margin_products\n",
    "FROM fact_product_performance\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDCB9 Overall Profitability Metrics:\")\n",
    "profitability.show(truncate=False)\n",
    "\n",
    "# ADVANCED ANALYTICS USING WINDOW FUNCTIONS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADVANCED ANALYTICS WITH WINDOW FUNCTIONS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a8179b0-23b4-49be-8501-c6bf6104a02b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 11. CUSTOMER RETENTION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d15fd3c1-243c-46d5-b8a0-6df6dac8f0b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n11. CUSTOMER RETENTION & ENGAGEMENT\n----------------------------------------\n\uD83D\uDD04 Customer Retention by Segment:\n+---------------+---------------+-----------------+---------------+-----------------------+\n|CustomerSegment|total_customers|avg_active_months|avg_tenure_days|engagement_rate_percent|\n+---------------+---------------+-----------------+---------------+-----------------------+\n|Domestic       |1000           |11.99            |357.31         |99.93                  |\n+---------------+---------------+-----------------+---------------+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 11. CUSTOMER RETENTION ANALYSIS\n",
    "print(\"\\n11. CUSTOMER RETENTION & ENGAGEMENT\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "customer_retention = spark.sql(\"\"\"\n",
    "WITH customer_months AS (\n",
    "    SELECT \n",
    "        c.CustomerKey,\n",
    "        c.FullName,\n",
    "        c.CustomerSegment,\n",
    "        COUNT(DISTINCT CONCAT(f.Year, '-', LPAD(f.Month, 2, '0'))) as active_months,\n",
    "        DATEDIFF(MAX(f.DateKey), MIN(f.DateKey)) as customer_tenure_days\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_customer c ON f.CustomerKey = c.CustomerKey\n",
    "    GROUP BY c.CustomerKey, c.FullName, c.CustomerSegment\n",
    ")\n",
    "SELECT \n",
    "    CustomerSegment,\n",
    "    COUNT(*) as total_customers,\n",
    "    ROUND(AVG(active_months), 2) as avg_active_months,\n",
    "    ROUND(AVG(customer_tenure_days), 2) as avg_tenure_days,\n",
    "    ROUND(AVG(active_months) / 12 * 100, 2) as engagement_rate_percent\n",
    "FROM customer_months\n",
    "GROUP BY CustomerSegment\n",
    "ORDER BY engagement_rate_percent DESC\n",
    "\"\"\")\n",
    "print(\"\uD83D\uDD04 Customer Retention by Segment:\")\n",
    "customer_retention.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5062acab-d62a-437a-83bf-751efc68eb66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 12. PRODUCT CATEGORY GROWTH ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8efec371-b4af-45ff-b7fd-ce77078fdaf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n12. CATEGORY GROWTH TRENDS\n----------------------------------------\n\uD83D\uDCCA Category Monthly Growth Rates:\n+--------+----+-----+------------------+-----------+---------------+\n|Category|Year|Month|monthly_revenue   |growth_rate|growth_category|\n+--------+----+-----+------------------+-----------+---------------+\n|1       |2024|2    |2472053.62        |-4.77      |Declining      |\n|1       |2024|3    |2700300.6900000013|9.23       |Moderate Growth|\n|1       |2024|4    |2764199.8600000013|2.37       |Moderate Growth|\n|1       |2024|5    |2911093.100000003 |5.31       |Moderate Growth|\n|1       |2024|6    |2687559.920000002 |-7.68      |Declining      |\n|1       |2024|7    |2786858.3400000017|3.69       |Moderate Growth|\n|1       |2024|8    |2673765.040000002 |-4.06      |Declining      |\n|1       |2024|9    |2761369.620000002 |3.28       |Moderate Growth|\n|1       |2024|10   |2853743.9300000016|3.35       |Moderate Growth|\n|1       |2024|11   |2551802.750000002 |-10.58     |Declining      |\n|1       |2024|12   |2706931.900000002 |6.08       |Moderate Growth|\n|2       |2024|2    |398457.46         |-7.76      |Declining      |\n|2       |2024|3    |445202.3699999998 |11.73      |High Growth    |\n|2       |2024|4    |415176.32000000007|-6.74      |Declining      |\n|2       |2024|5    |473192.53         |13.97      |High Growth    |\n|2       |2024|6    |408408.3900000001 |-13.69     |Declining      |\n|2       |2024|7    |454339.99         |11.25      |High Growth    |\n|2       |2024|8    |454035.2099999999 |-0.07      |Declining      |\n|2       |2024|9    |418061.77         |-7.92      |Declining      |\n|2       |2024|10   |468055.57999999996|11.96      |High Growth    |\n+--------+----+-----+------------------+-----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 12. PRODUCT CATEGORY GROWTH ANALYSIS\n",
    "print(\"\\n12. CATEGORY GROWTH TRENDS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "category_growth = spark.sql(\"\"\"\n",
    "WITH monthly_category_sales AS (\n",
    "    SELECT \n",
    "        p.Category,\n",
    "        f.Year,\n",
    "        f.Month,\n",
    "        SUM(f.TotalSales) as monthly_revenue\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_product p ON f.ProductKey = p.ProductKey\n",
    "    GROUP BY p.Category, f.Year, f.Month\n",
    "),\n",
    "category_growth AS (\n",
    "    SELECT \n",
    "        Category,\n",
    "        Year,\n",
    "        Month,\n",
    "        monthly_revenue,\n",
    "        LAG(monthly_revenue) OVER (PARTITION BY Category ORDER BY Year, Month) as prev_month_revenue,\n",
    "        CASE \n",
    "            WHEN LAG(monthly_revenue) OVER (PARTITION BY Category ORDER BY Year, Month) IS NOT NULL \n",
    "            THEN ROUND((monthly_revenue - LAG(monthly_revenue) OVER (PARTITION BY Category ORDER BY Year, Month)) / \n",
    "                  LAG(monthly_revenue) OVER (PARTITION BY Category ORDER BY Year, Month) * 100, 2)\n",
    "            ELSE NULL\n",
    "        END as growth_rate\n",
    "    FROM monthly_category_sales\n",
    ")\n",
    "SELECT \n",
    "    Category,\n",
    "    Year,\n",
    "    Month,\n",
    "    monthly_revenue,\n",
    "    growth_rate,\n",
    "    CASE \n",
    "        WHEN growth_rate > 10 THEN 'High Growth'\n",
    "        WHEN growth_rate > 0 THEN 'Moderate Growth' \n",
    "        WHEN growth_rate < 0 THEN 'Declining'\n",
    "        ELSE 'Stable'\n",
    "    END as growth_category\n",
    "FROM category_growth\n",
    "WHERE growth_rate IS NOT NULL\n",
    "ORDER BY Category, Year, Month\n",
    "LIMIT 20\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDCCA Category Monthly Growth Rates:\")\n",
    "category_growth.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "257e340f-7543-45e3-b968-6582048494cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 13. CUSTOMER ACQUISITION TRENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1affc819-1175-40d2-9a95-62bc0b7237a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n13. CUSTOMER ACQUISITION ANALYSIS\n----------------------------------------\n\uD83C\uDD95 New Customer Acquisition by Month:\n+----------------+-----------------+-------------+--------------------+\n|acquisition_year|acquisition_month|new_customers|cumulative_customers|\n+----------------+-----------------+-------------+--------------------+\n|2024            |1                |1000         |1000                |\n+----------------+-----------------+-------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 13. CUSTOMER ACQUISITION TRENDS\n",
    "print(\"\\n13. CUSTOMER ACQUISITION ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "customer_acquisition = spark.sql(\"\"\"\n",
    "WITH first_purchases AS (\n",
    "    SELECT \n",
    "        CustomerKey,\n",
    "        MIN(DateKey) as first_purchase_date,\n",
    "        MONTH(MIN(DateKey)) as acquisition_month,\n",
    "        YEAR(MIN(DateKey)) as acquisition_year\n",
    "    FROM fact_sales\n",
    "    GROUP BY CustomerKey\n",
    ")\n",
    "SELECT \n",
    "    acquisition_year,\n",
    "    acquisition_month,\n",
    "    COUNT(*) as new_customers,\n",
    "    SUM(COUNT(*)) OVER (ORDER BY acquisition_year, acquisition_month) as cumulative_customers\n",
    "FROM first_purchases\n",
    "GROUP BY acquisition_year, acquisition_month\n",
    "ORDER BY acquisition_year, acquisition_month\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83C\uDD95 New Customer Acquisition by Month:\")\n",
    "customer_acquisition.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c749e85f-d840-4f10-8633-e42ccf0ade22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 14. CROSS-SELLING OPPORTUNITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66690f02-774e-407f-9680-b8d3cbf8825c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n14. CROSS-SELLING & BUNDLING OPPORTUNITIES\n----------------------------------------\n\uD83D\uDECD️ Top Product Combinations Purchased Together:\n+---------+---------+--------------+----------------+\n|product_a|product_b|purchase_count|co_purchase_rate|\n+---------+---------+--------------+----------------+\n+---------+---------+--------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 14. CROSS-SELLING OPPORTUNITIES\n",
    "print(\"\\n14. CROSS-SELLING & BUNDLING OPPORTUNITIES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "cross_selling = spark.sql(\"\"\"\n",
    "WITH product_pairs AS (\n",
    "    SELECT \n",
    "        f1.ProductKey as product1,\n",
    "        f2.ProductKey as product2,\n",
    "        COUNT(*) as purchase_count\n",
    "    FROM fact_sales f1\n",
    "    JOIN fact_sales f2 ON f1.TransactionID = f2.TransactionID AND f1.ProductKey < f2.ProductKey\n",
    "    GROUP BY f1.ProductKey, f2.ProductKey\n",
    "    HAVING COUNT(*) > 10\n",
    ")\n",
    "SELECT \n",
    "    p1.ProductName as product_a,\n",
    "    p2.ProductName as product_b,\n",
    "    pp.purchase_count,\n",
    "    ROUND(pp.purchase_count * 100.0 / (SELECT COUNT(DISTINCT TransactionID) FROM fact_sales), 2) as co_purchase_rate\n",
    "FROM product_pairs pp\n",
    "JOIN dim_product p1 ON pp.product1 = p1.ProductKey\n",
    "JOIN dim_product p2 ON pp.product2 = p2.ProductKey\n",
    "ORDER BY pp.purchase_count DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDECD️ Top Product Combinations Purchased Together:\")\n",
    "cross_selling.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c301bd15-de51-44b8-b5b0-4c2d45a6ad0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 15. KEY PERFORMANCE INDICATORS (KPIs) DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1822e340-a615-42c6-ae9d-d6733b0f3e76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nBUSINESS INTELLIGENCE DASHBOARD - KEY PERFORMANCE INDICATORS\n================================================================================\n\uD83D\uDCCA BUSINESS INTELLIGENCE DASHBOARD:\n+-------------+-------------+---------------------+---------------------+---------------+------------------+-----------------------------+----------------------------+---------------+------------------+----------------+-------------------------+\n|total_revenue|total_profit |overall_profit_margin|avg_transaction_value|total_customers|avg_customer_value|avg_transactions_per_customer|platinum_customer_percentage|active_products|avg_product_margin|total_units_sold|avg_units_per_transaction|\n+-------------+-------------+---------------------+---------------------+---------------+------------------+-----------------------------+----------------------------+---------------+------------------+----------------+-------------------------+\n|5.66662938E7 |4.431235687E7|78.2                 |668.5                |1000           |56666.29          |84.77                        |100.00                      |200            |78.1              |254676          |3.00                     |\n+-------------+-------------+---------------------+---------------------+---------------+------------------+-----------------------------+----------------------------+---------------+------------------+----------------+-------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 15. KEY PERFORMANCE INDICATORS (KPIs) DASHBOARD\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUSINESS INTELLIGENCE DASHBOARD - KEY PERFORMANCE INDICATORS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "kpi_dashboard = spark.sql(\"\"\"\n",
    "WITH base_metrics AS (\n",
    "    -- Revenue Metrics\n",
    "    SELECT \n",
    "        SUM(TotalSales) as total_revenue,\n",
    "        SUM(Profit) as total_profit,\n",
    "        COUNT(DISTINCT TransactionID) as total_transactions,\n",
    "        COUNT(DISTINCT CustomerKey) as total_customers,\n",
    "        SUM(Quantity) as total_units_sold\n",
    "    FROM fact_sales\n",
    "),\n",
    "customer_metrics AS (\n",
    "    -- Customer Metrics\n",
    "    SELECT \n",
    "        AVG(TotalSpend) as avg_customer_lifetime_value,\n",
    "        AVG(TotalTransactions) as avg_transactions_per_customer,\n",
    "        COUNT(CASE WHEN CustomerValueSegment = 'Platinum' THEN 1 END) as platinum_customers,\n",
    "        COUNT(CASE WHEN CustomerValueSegment = 'Gold' THEN 1 END) as gold_customers\n",
    "    FROM fact_customer_metrics\n",
    "),\n",
    "product_metrics AS (\n",
    "    -- Product Metrics\n",
    "    SELECT \n",
    "        AVG(ProfitMargin) as avg_profit_margin,\n",
    "        COUNT(DISTINCT ProductKey) as active_products,\n",
    "        SUM(TotalUnitsSold) as total_product_units\n",
    "    FROM fact_product_performance\n",
    ")\n",
    "SELECT \n",
    "    -- Revenue KPIs\n",
    "    ROUND(bm.total_revenue, 2) as total_revenue,\n",
    "    ROUND(bm.total_profit, 2) as total_profit,\n",
    "    ROUND((bm.total_profit / bm.total_revenue) * 100, 2) as overall_profit_margin,\n",
    "    ROUND(bm.total_revenue / bm.total_transactions, 2) as avg_transaction_value,\n",
    "    \n",
    "    -- Customer KPIs\n",
    "    bm.total_customers,\n",
    "    ROUND(cm.avg_customer_lifetime_value, 2) as avg_customer_value,\n",
    "    ROUND(cm.avg_transactions_per_customer, 2) as avg_transactions_per_customer,\n",
    "    ROUND((cm.platinum_customers * 100.0 / bm.total_customers), 2) as platinum_customer_percentage,\n",
    "    \n",
    "    -- Product KPIs\n",
    "    pm.active_products,\n",
    "    ROUND(pm.avg_profit_margin, 2) as avg_product_margin,\n",
    "    bm.total_units_sold,\n",
    "    ROUND(bm.total_units_sold * 1.0 / bm.total_transactions, 2) as avg_units_per_transaction\n",
    "    \n",
    "FROM base_metrics bm, customer_metrics cm, product_metrics pm\n",
    "\"\"\")\n",
    "\n",
    "print(\"\uD83D\uDCCA BUSINESS INTELLIGENCE DASHBOARD:\")\n",
    "kpi_dashboard.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bad38f52-a5ba-4c26-afcb-7b338fc08225",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  16. RECOMMENDATION ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4e8b15b-d4fa-4624-b19f-0996eced21c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nDATA-DRIVEN BUSINESS RECOMMENDATIONS\n================================================================================\n\uD83D\uDCA1 STRATEGIC RECOMMENDATIONS:\n1. Customer Focus:\n+--------------------------------------------------------------------+------------------+\n|recommendation                                                      |category          |\n+--------------------------------------------------------------------+------------------+\n|Focus on Platinum & Gold customers who drive 100.0% of total revenue|Customer Retention|\n+--------------------------------------------------------------------+------------------+\n\n2. Product Optimization:\n+---------------------------------------------------------------------------+----------------+\n|recommendation                                                             |category        |\n+---------------------------------------------------------------------------+----------------+\n|Review and optimize 7 category with 77.0% profit margin (lowest performing)|Product Strategy|\n+---------------------------------------------------------------------------+----------------+\n\n3. Product Improvement Opportunity:\n+----------------------------------------------------------+----------------+\n|recommendation                                            |category        |\n+----------------------------------------------------------+----------------+\n|Improve 7 category performance (77.0% margin vs avg 78.2%)|Product Strategy|\n+----------------------------------------------------------+----------------+\n\n4. Store Strategy:\n+-----------------------------------------------+----------------+\n|recommendation                                 |category        |\n+-----------------------------------------------+----------------+\n|Focus on top-performing Southeast region stores|Store Operations|\n+-----------------------------------------------+----------------+\n\n5. Marketing Strategy:\n+------------------------------------------------------------+------------------+\n|recommendation                                              |category          |\n+------------------------------------------------------------+------------------+\n|Plan promotions for 5/2024 - peak revenue month (5026723.06)|Marketing Strategy|\n+------------------------------------------------------------+------------------+\n\n\n\uD83D\uDCCA ALTERNATIVE RECOMMENDATIONS BASED ON DATA ANALYSIS:\n\uD83D\uDCCD Store Operations: Focus on Southeast region stores (highest revenue generator)\n\uD83D\uDC65 Customer Retention: Platinum & Gold customers drive 100.0% of total revenue\n\uD83D\uDCE6 Product Strategy: Review and optimize 7 category with 77.0% profit margin (lowest performing)\n\uD83D\uDCCA Industry Benchmark: Average category profit margin is 78.2%\n\uD83D\uDCC5 Marketing Strategy: Plan promotions for 2024-05 (peak revenue month: $5,026,723.06)\n\n================================================================================\nANALYSIS COMPLETE - KEY INSIGHTS SUMMARY\n================================================================================\n\n\uD83D\uDCC8 KEY BUSINESS METRICS SUMMARY:\n\uD83D\uDCB0 Revenue: $56,666,293.80\n\uD83D\uDCB9 Profit: $44,312,356.87\n\uD83D\uDCCA Profit Margin: 78.20%\n\uD83D\uDED2 Transactions: 84,766\n\uD83D\uDC65 Customers: 1,000\n\n\uD83C\uDFAF Customer Segmentation:\n   Platinum: 1000 customers\n   Gold: 0 customers\n   Silver: 0 customers\n   Bronze: 0 customers\n\n\uD83C\uDFC6 Top 3 Categories by Revenue:\n   1: $32,465,491.02 (78.2% margin)\n   8: $5,526,959.78 (78.5% margin)\n   2: $5,227,575.20 (78.3% margin)\n\n\uD83D\uDCCA Category Profit Margin Range:\n   Lowest: 77.0%\n   Highest: 79.0%\n   Average: 78.2%\n\n\uD83C\uDFEA Top 3 Stores by Revenue:\n   Atlanta Plaza (Southeast): $5,866,695.36\n   Phoenix Mall (Southwest): $5,730,289.63\n   Miami Beach Store (Southeast): $5,718,847.14\n\n\uD83C\uDFAF KEY BUSINESS INSIGHTS:\n\n1. REVENUE & PROFITABILITY:\n   - Clear view of total revenue, profit, and margins\n   - Transaction volume and customer base size\n   - Seasonal revenue patterns\n\n2. CUSTOMER INSIGHTS:\n   - Customer value segmentation distribution\n   - High-value customer contribution to revenue\n   - Customer behavior patterns by segment\n\n3. PRODUCT PERFORMANCE:\n   - Top-performing categories and their margins\n   - Product portfolio profitability\n   - Cross-selling opportunities\n\n4. OPERATIONAL EFFICIENCY:\n   - Store performance rankings\n   - Regional performance variations\n   - Transaction efficiency metrics\n\n5. GROWTH OPPORTUNITIES:\n   - Identify lowest-performing categories for optimization\n   - Seasonal trends for strategic planning\n   - Customer acquisition and retention strategies\n\nNEXT STEPS:\n- Implement targeted marketing for high-value segments\n- Optimize inventory for top-performing categories\n- Focus resources on highest-performing regions\n- Develop seasonal promotion strategies\n- Monitor KPIs for continuous improvement\n\n\n✅ Gold Layer Analysis Completed Successfully!\n"
     ]
    }
   ],
   "source": [
    "# 16. RECOMMENDATION ENGINE - FIXED VERSION\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA-DRIVEN BUSINESS RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Fix the UNION queries by running them separately\n",
    "print(\"\uD83D\uDCA1 STRATEGIC RECOMMENDATIONS:\")\n",
    "\n",
    "# Recommendation 1: Focus on High-Value Customers\n",
    "recommendation1 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CONCAT('Focus on Platinum & Gold customers who drive ', \n",
    "           ROUND(SUM(SegmentRevenue) / (SELECT SUM(SegmentRevenue) FROM customer_segmentation_kpi) * 100, 1), \n",
    "           '% of total revenue') as recommendation,\n",
    "    'Customer Retention' as category\n",
    "FROM customer_segmentation_kpi \n",
    "WHERE CustomerValueSegment IN ('Platinum', 'Gold')\n",
    "\"\"\")\n",
    "print(\"1. Customer Focus:\")\n",
    "recommendation1.show(truncate=False)\n",
    "\n",
    "# Recommendation 2: Optimize Low-Performing Categories - FIXED\n",
    "recommendation2 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CONCAT('Review and optimize ', Category, ' category with ', \n",
    "           ROUND(ProfitMargin, 1), '% profit margin (lowest performing)') as recommendation,\n",
    "    'Product Strategy' as category\n",
    "FROM category_performance_kpi \n",
    "WHERE ProfitMargin = (SELECT MIN(ProfitMargin) FROM category_performance_kpi)\n",
    "LIMIT 1\n",
    "\"\"\")\n",
    "print(\"2. Product Optimization:\")\n",
    "recommendation2.show(truncate=False)\n",
    "\n",
    "# Alternative: If we still want to show improvement opportunities for categories below average\n",
    "recommendation2_alt = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CONCAT('Improve ', Category, ' category performance (', \n",
    "           ROUND(ProfitMargin, 1), '% margin vs avg ', \n",
    "           ROUND((SELECT AVG(ProfitMargin) FROM category_performance_kpi), 1), '%)') as recommendation,\n",
    "    'Product Strategy' as category\n",
    "FROM category_performance_kpi \n",
    "WHERE ProfitMargin < (SELECT AVG(ProfitMargin) FROM category_performance_kpi)\n",
    "ORDER BY ProfitMargin ASC \n",
    "LIMIT 1\n",
    "\"\"\")\n",
    "print(\"3. Product Improvement Opportunity:\")\n",
    "recommendation2_alt.show(truncate=False)\n",
    "\n",
    "# Recommendation 3: Store Performance Optimization\n",
    "recommendation3 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CONCAT('Focus on top-performing ', Region, ' region stores') as recommendation,\n",
    "    'Store Operations' as category\n",
    "FROM (\n",
    "    SELECT Region\n",
    "    FROM (\n",
    "        SELECT \n",
    "            s.Region,\n",
    "            SUM(f.TotalSales) as total_revenue\n",
    "        FROM fact_sales f\n",
    "        JOIN dim_store s ON f.StoreKey = s.StoreKey\n",
    "        GROUP BY s.Region\n",
    "        ORDER BY total_revenue DESC\n",
    "        LIMIT 1\n",
    "    )\n",
    ")\n",
    "\"\"\")\n",
    "print(\"4. Store Strategy:\")\n",
    "recommendation3.show(truncate=False)\n",
    "\n",
    "# Recommendation 4: Seasonal Strategy\n",
    "recommendation4 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CONCAT('Plan promotions for ', \n",
    "           Month, '/', Year, \n",
    "           ' - peak revenue month (', \n",
    "           ROUND(MonthlyRevenue, 2), ')') as recommendation,\n",
    "    'Marketing Strategy' as category\n",
    "FROM monthly_revenue_kpi \n",
    "WHERE MonthlyRevenue = (SELECT MAX(MonthlyRevenue) FROM monthly_revenue_kpi)\n",
    "LIMIT 1\n",
    "\"\"\")\n",
    "print(\"5. Marketing Strategy:\")\n",
    "recommendation4.show(truncate=False)\n",
    "\n",
    "# Alternative approach: Create recommendations using Python logic\n",
    "print(\"\\n\uD83D\uDCCA ALTERNATIVE RECOMMENDATIONS BASED ON DATA ANALYSIS:\")\n",
    "\n",
    "# Get top performing region\n",
    "top_region = spark.sql(\"\"\"\n",
    "SELECT Region, SUM(total_revenue) as region_revenue\n",
    "FROM (\n",
    "    SELECT \n",
    "        s.Region,\n",
    "        SUM(f.TotalSales) as total_revenue\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_store s ON f.StoreKey = s.StoreKey\n",
    "    GROUP BY s.Region\n",
    ")\n",
    "GROUP BY Region\n",
    "ORDER BY region_revenue DESC\n",
    "LIMIT 1\n",
    "\"\"\").collect()[0]['Region']\n",
    "\n",
    "print(f\"\uD83D\uDCCD Store Operations: Focus on {top_region} region stores (highest revenue generator)\")\n",
    "\n",
    "# Get customer segment contribution\n",
    "segment_contribution = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    ROUND(SUM(SegmentRevenue) / (SELECT SUM(SegmentRevenue) FROM customer_segmentation_kpi) * 100, 1) as contribution_percent\n",
    "FROM customer_segmentation_kpi \n",
    "WHERE CustomerValueSegment IN ('Platinum', 'Gold')\n",
    "\"\"\").collect()[0]['contribution_percent']\n",
    "\n",
    "print(f\"\uD83D\uDC65 Customer Retention: Platinum & Gold customers drive {segment_contribution}% of total revenue\")\n",
    "\n",
    "# Get lowest performing category (even if all are above 15%)\n",
    "low_category = spark.sql(\"\"\"\n",
    "SELECT Category, ProfitMargin\n",
    "FROM category_performance_kpi \n",
    "ORDER BY ProfitMargin ASC \n",
    "LIMIT 1\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "print(f\"\uD83D\uDCE6 Product Strategy: Review and optimize {low_category['Category']} category with {low_category['ProfitMargin']:.1f}% profit margin (lowest performing)\")\n",
    "\n",
    "# Get average profit margin for context\n",
    "avg_margin = spark.sql(\"\"\"\n",
    "SELECT ROUND(AVG(ProfitMargin), 1) as avg_margin\n",
    "FROM category_performance_kpi\n",
    "\"\"\").collect()[0]['avg_margin']\n",
    "\n",
    "print(f\"\uD83D\uDCCA Industry Benchmark: Average category profit margin is {avg_margin}%\")\n",
    "\n",
    "# Get peak revenue month\n",
    "peak_month = spark.sql(\"\"\"\n",
    "SELECT Year, Month, MonthlyRevenue\n",
    "FROM monthly_revenue_kpi \n",
    "ORDER BY MonthlyRevenue DESC\n",
    "LIMIT 1\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "print(f\"\uD83D\uDCC5 Marketing Strategy: Plan promotions for {peak_month['Year']}-{peak_month['Month']:02d} (peak revenue month: ${peak_month['MonthlyRevenue']:,.2f})\")\n",
    "\n",
    "# FINAL SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE - KEY INSIGHTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show key metrics summary\n",
    "print(\"\\n\uD83D\uDCC8 KEY BUSINESS METRICS SUMMARY:\")\n",
    "\n",
    "# Overall business metrics\n",
    "overall_metrics = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    ROUND(SUM(TotalSales), 2) as total_revenue,\n",
    "    ROUND(SUM(Profit), 2) as total_profit,\n",
    "    ROUND((SUM(Profit) / SUM(TotalSales)) * 100, 2) as profit_margin_percent,\n",
    "    COUNT(DISTINCT TransactionID) as total_transactions,\n",
    "    COUNT(DISTINCT CustomerKey) as total_customers\n",
    "FROM fact_sales\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "print(f\"\uD83D\uDCB0 Revenue: ${overall_metrics['total_revenue']:,.2f}\")\n",
    "print(f\"\uD83D\uDCB9 Profit: ${overall_metrics['total_profit']:,.2f}\")\n",
    "print(f\"\uD83D\uDCCA Profit Margin: {overall_metrics['profit_margin_percent']:.2f}%\")\n",
    "print(f\"\uD83D\uDED2 Transactions: {overall_metrics['total_transactions']:,}\")\n",
    "print(f\"\uD83D\uDC65 Customers: {overall_metrics['total_customers']:,}\")\n",
    "\n",
    "# Customer segmentation summary\n",
    "customer_summary = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    SUM(CASE WHEN CustomerValueSegment = 'Platinum' THEN CustomerCount ELSE 0 END) as platinum_customers,\n",
    "    SUM(CASE WHEN CustomerValueSegment = 'Gold' THEN CustomerCount ELSE 0 END) as gold_customers,\n",
    "    SUM(CASE WHEN CustomerValueSegment = 'Silver' THEN CustomerCount ELSE 0 END) as silver_customers,\n",
    "    SUM(CASE WHEN CustomerValueSegment = 'Bronze' THEN CustomerCount ELSE 0 END) as bronze_customers\n",
    "FROM customer_segmentation_kpi\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "print(f\"\\n\uD83C\uDFAF Customer Segmentation:\")\n",
    "print(f\"   Platinum: {customer_summary['platinum_customers']} customers\")\n",
    "print(f\"   Gold: {customer_summary['gold_customers']} customers\") \n",
    "print(f\"   Silver: {customer_summary['silver_customers']} customers\")\n",
    "print(f\"   Bronze: {customer_summary['bronze_customers']} customers\")\n",
    "\n",
    "# Top performing categories\n",
    "top_categories = spark.sql(\"\"\"\n",
    "SELECT Category, CategoryRevenue, ProfitMargin\n",
    "FROM category_performance_kpi\n",
    "ORDER BY CategoryRevenue DESC\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n\uD83C\uDFC6 Top 3 Categories by Revenue:\")\n",
    "for row in top_categories.collect():\n",
    "    print(f\"   {row['Category']}: ${row['CategoryRevenue']:,.2f} ({row['ProfitMargin']:.1f}% margin)\")\n",
    "\n",
    "# Category performance range for context\n",
    "category_range = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    MIN(ProfitMargin) as min_margin,\n",
    "    MAX(ProfitMargin) as max_margin,\n",
    "    AVG(ProfitMargin) as avg_margin\n",
    "FROM category_performance_kpi\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "print(f\"\\n\uD83D\uDCCA Category Profit Margin Range:\")\n",
    "print(f\"   Lowest: {category_range['min_margin']:.1f}%\")\n",
    "print(f\"   Highest: {category_range['max_margin']:.1f}%\")\n",
    "print(f\"   Average: {category_range['avg_margin']:.1f}%\")\n",
    "\n",
    "# Store performance summary\n",
    "store_summary = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    s.StoreName,\n",
    "    s.Region,\n",
    "    SUM(f.TotalSales) as revenue\n",
    "FROM fact_sales f\n",
    "JOIN dim_store s ON f.StoreKey = s.StoreKey\n",
    "GROUP BY s.StoreName, s.Region\n",
    "ORDER BY revenue DESC\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n\uD83C\uDFEA Top 3 Stores by Revenue:\")\n",
    "for row in store_summary.collect():\n",
    "    print(f\"   {row['StoreName']} ({row['Region']}): ${row['revenue']:,.2f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "\uD83C\uDFAF KEY BUSINESS INSIGHTS:\n",
    "\n",
    "1. REVENUE & PROFITABILITY:\n",
    "   - Clear view of total revenue, profit, and margins\n",
    "   - Transaction volume and customer base size\n",
    "   - Seasonal revenue patterns\n",
    "\n",
    "2. CUSTOMER INSIGHTS:\n",
    "   - Customer value segmentation distribution\n",
    "   - High-value customer contribution to revenue\n",
    "   - Customer behavior patterns by segment\n",
    "\n",
    "3. PRODUCT PERFORMANCE:\n",
    "   - Top-performing categories and their margins\n",
    "   - Product portfolio profitability\n",
    "   - Cross-selling opportunities\n",
    "\n",
    "4. OPERATIONAL EFFICIENCY:\n",
    "   - Store performance rankings\n",
    "   - Regional performance variations\n",
    "   - Transaction efficiency metrics\n",
    "\n",
    "5. GROWTH OPPORTUNITIES:\n",
    "   - Identify lowest-performing categories for optimization\n",
    "   - Seasonal trends for strategic planning\n",
    "   - Customer acquisition and retention strategies\n",
    "\n",
    "NEXT STEPS:\n",
    "- Implement targeted marketing for high-value segments\n",
    "- Optimize inventory for top-performing categories\n",
    "- Focus resources on highest-performing regions\n",
    "- Develop seasonal promotion strategies\n",
    "- Monitor KPIs for continuous improvement\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✅ Gold Layer Analysis Completed Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bda1b3e0-dc18-41b4-930e-5007d8347496",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. TARGETED MARKETING FOR HIGH-VALUE SEGMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee0a6f41-57ac-4f47-a1ab-1d2fadd814be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. OPTIMIZE INVENTORY FOR TOP-PERFORMING CATEGORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49485651-1c73-488b-9ffe-abb862203e06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3. FOCUS RESOURCES ON HIGHEST-PERFORMING REGIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9036daf-ad85-4b97-b9aa-e1aa51d774b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4. DEVELOP SEASONAL PROMOTION STRATEGIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf6133a1-8496-4d30-9ee9-52ad8de1b667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 5. MONITOR KPIs FOR CONTINUOUS IMPROVEMENT"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4- Gold Layer Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}